{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Bkl2oM1Ggh",
        "outputId": "6794d0c0-d294-4515-8c8b-f0650eb3a274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "import sklearn\n",
        "import matplotlib.image as mpimg\n",
        "import keras "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcPsk1zlILX2"
      },
      "source": [
        "!unzip ./drive/My\\ Drive/data.zip -d ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwBZT2c01m7V"
      },
      "source": [
        "# Create generator for dataset with images and steering measurements\n",
        "\n",
        "# path where the data is stored \n",
        "path = './data' \n",
        "\n",
        "# read in the csv lines \n",
        "samples = []\n",
        "with open(path+'/driving_log.csv') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for line in reader: \n",
        "        samples.append(line)\n",
        "\n",
        "# split csv lines into test, validation, and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_samples, test_samples = train_test_split(samples, test_size=.2)\n",
        "test_samples, valid_samples = train_test_split(samples, test_size=.25)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwYRf3fl1r0w"
      },
      "source": [
        "def generator(samples, batch_size=32):\n",
        "    while True: \n",
        "        sklearn.utils.shuffle(samples)\n",
        "        # for each batch\n",
        "        for start in range(0, len(samples), batch_size//2): # batch size is divided by 2 because we add the flipped images as well\n",
        "            batch_samples = samples[start:start+batch_size]\n",
        "\n",
        "            images = []\n",
        "            angles = []\n",
        "\n",
        "            # for each csv line\n",
        "            for batch_sample in batch_samples:\n",
        "                \n",
        "                # get image path\n",
        "                name = path+'/IMG/'+batch_sample[0].split('\\\\')[-1]\n",
        "                \n",
        "                # add image and angle\n",
        "                center_image = mpimg.imread(name)\n",
        "                center_angle=float(batch_sample[3])\n",
        "                images.append(center_image)\n",
        "                angles.append(center_angle)\n",
        "                \n",
        "                # flip image \n",
        "                center_image_flip = np.fliplr(center_image)\n",
        "                center_angle_flip = -center_angle\n",
        "                images.append(center_image_flip)\n",
        "                angles.append(center_angle_flip)\n",
        "\n",
        "            X_train = np.array(images)\n",
        "            y_train = np.array(angles)\n",
        "            yield sklearn.utils.shuffle(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU5niQ-Z11Mn"
      },
      "source": [
        "# Build model\n",
        "\n",
        "# original shape of the image\n",
        "input_shape = (160,320,3)\n",
        "\n",
        "# first input layer of the model\n",
        "car_input = keras.layers.Input(shape=input_shape)\n",
        "\n",
        "# crop image to remove unnecessary \n",
        "cropped_input = keras.layers.Cropping2D(cropping=((50, 25), (0, 0)))(car_input)\n",
        "\n",
        "crop_input_shape = (85, 300, 3) # new input shape (85, 300, 3)\n",
        "\n",
        "# normalize image data\n",
        "normal_input = keras.layers.Lambda(lambda x: (x/255.0)-.5)(cropped_input)\n",
        "\n",
        "# resize to fit keras inception model\n",
        "resize_shape = 128\n",
        "resized_input = keras.layers.Lambda(lambda image: tf.image.resize_images( \n",
        "    image, (resize_shape, resize_shape)))(normal_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2op7wzD16pX"
      },
      "source": [
        "conv1 = keras.layers.Conv2D(16, (5,5), activation='relu')(resized_input)\n",
        "pool1 = keras.layers.MaxPooling2D()(conv1)\n",
        "\n",
        "conv2 = keras.layers.Conv2D(32, (5,5), activation='relu')(pool1)\n",
        "pool2 = keras.layers.MaxPooling2D()(conv2)\n",
        "\n",
        "conv3 = keras.layers.Conv2D(64, (5,5), activation='relu')(pool2)\n",
        "pool3 = keras.layers.MaxPooling2D()(conv3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLvkgE-j1-Gu"
      },
      "source": [
        "# flatten and add more fully connected layers to get steering measurement prediction\n",
        "flat = keras.layers.Flatten()(pool3)\n",
        "\n",
        "dropout1 = keras.layers.Dropout(.5)(flat)\n",
        "\n",
        "fc1 = keras.layers.Dense(1028, activation=tf.nn.relu)(dropout1)\n",
        "\n",
        "dropout2 = keras.layers.Dropout(.5)(fc1)\n",
        "\n",
        "fc2 = keras.layers.Dense(256, activation=tf.nn.relu)(dropout2)\n",
        "\n",
        "prediction = keras.layers.Dense(1)(fc2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hstUeVtA2F19",
        "outputId": "585c6c7a-5547-44dc-be1e-0188069895cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "# creates the model\n",
        "model = Model(inputs=car_input, outputs=prediction)\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='Adam', loss='mse')\n",
        "\n",
        "# check the summary of model to confirm architecture\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 160, 320, 3)       0         \n",
            "_________________________________________________________________\n",
            "cropping2d_3 (Cropping2D)    (None, 85, 320, 3)        0         \n",
            "_________________________________________________________________\n",
            "lambda_5 (Lambda)            (None, 85, 320, 3)        0         \n",
            "_________________________________________________________________\n",
            "lambda_6 (Lambda)            (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 124, 124, 16)      1216      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 62, 62, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 58, 58, 32)        12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 29, 29, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 25, 25, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1028)              9475076   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1028)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               263424    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 9,804,069\n",
            "Trainable params: 9,804,069\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-agew992JNH"
      },
      "source": [
        "batch_size = 32\n",
        "from math import ceil\n",
        "\n",
        "train_generator = generator(train_samples, batch_size=batch_size)\n",
        "valid_generator = generator(valid_samples, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCS_Q-Xs2YPm",
        "outputId": "867f18e2-4e9f-495f-db6e-4c22b1705527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "history = model.fit_generator(train_generator, \n",
        "            steps_per_epoch=ceil(len(train_samples)/batch_size), \n",
        "            validation_data=valid_generator, \n",
        "            validation_steps=ceil(len(valid_samples)/batch_size), \n",
        "            epochs=5, verbose=1)\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "275/275 [==============================] - 25s 92ms/step - loss: 0.0200 - val_loss: 0.0083\n",
            "Epoch 2/5\n",
            "275/275 [==============================] - 23s 85ms/step - loss: 0.0186 - val_loss: 0.0101\n",
            "Epoch 3/5\n",
            "275/275 [==============================] - 23s 84ms/step - loss: 0.0174 - val_loss: 0.0068\n",
            "Epoch 4/5\n",
            "275/275 [==============================] - 23s 85ms/step - loss: 0.0170 - val_loss: 0.0078\n",
            "Epoch 5/5\n",
            "275/275 [==============================] - 23s 85ms/step - loss: 0.0156 - val_loss: 0.0051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipj81NJvKFRh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}